---
title: "DMS_Meta"
author: "T.L"
date: "2024-05-07"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Libraries
```{r}

library(tidyverse) # data wrangling
library(janitor) # clean column names
library(metafor) # compute effect sizes
library(effectsize)# compute effect sizes
library(clubSandwich)
library(TOSTER)

source("compute_es.R")
source("conduct_mlma.R")
source("table_es_overview.R")
source("conduct_sensitivity_rho.R")
source("plot_sensitivity_rho.R")
source("plot_forestplot_ma.R")


```


# Clean up data
```{r}

data <- read.csv(file = "2024-0520_review_Formatted.csv", header = TRUE)

data <- clean_names(data)

sapply(data, class)

# Clean up culture column into separate 

df1 <- data %>% separate(culture_of_sample_study_1, 
                         c("culture_powerdistance", "culture_individualism",
                           "culture_mtas", "culture_uncertaintyavoidance",
                           "culture_longtermorientation", "culture_indulgence"), 
                         ";")

df1$culture_powerdistance<-gsub("PD:","",as.character(df1$culture_powerdistance))
df1$culture_individualism<-gsub("Individualism:","",as.character(df1$culture_individualism))
df1$culture_mtas<-gsub("MTAS:","",as.character(df1$culture_mtas))
df1$culture_uncertaintyavoidance<-gsub("UA:","",as.character(df1$culture_uncertaintyavoidance))
df1$culture_longtermorientation<-gsub("LTO:","",as.character(df1$culture_longtermorientation))
df1$culture_indulgence<-gsub("Indulgence:","",as.character(df1$culture_indulgence))

sapply(df1, class)

df1$culture_powerdistance <- as.numeric(df1$culture_powerdistance)
df1$culture_individualism <- as.numeric(df1$culture_individualism)
df1$culture_mtas <- as.numeric(df1$culture_mtas)
df1$culture_uncertaintyavoidance <- as.numeric(df1$culture_uncertaintyavoidance)
df1$culture_longtermorientation <- as.numeric(df1$culture_longtermorientation)
df1$culture_indulgence <- as.numeric(df1$culture_indulgence)

# Fix up some names

df1 <- df1 %>% rename(country = country_in_which_the_study_conducted)

df1$country<-gsub("Other:","",as.character(df1$country))

df1 <- df1 %>% rename(context = topic_of_decision_important_general_unknown_etc_study_1)

df1 <- df1 %>% rename(measure = type_of_avoidant_decision_making_measure_study_1)

df1 <- df1 %>% rename(sample_type = population_description_study_1)

df1 <- df1 %>% rename(analysis = analysis_type_study_1_avoidant_dv)

df1 <- df1 %>% mutate_all(na_if, "")

write.csv(df1, file = "prepped_meta_data.csv")

```


# Compute Effect Sizes
```{r}


df2 <- read.csv(file = "prepped_meta_data.csv")

compute_es(df2)

```


## Visualisation and overview table of data
```{r}

dat <- read.csv(file = "effect_sizes.csv", header = TRUE)

## There are duplicate rows - Unsure why. ## FIXED IT!!



dat %>% 
  ggplot(aes(x= cor_yi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= cor_vi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= log10(n_incl_es))) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample")

dat %>% 
  ggplot(aes(x= dec_diff)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample age Differences (decades)")



table1 <- table_es_overview(dat)

table1

```


# Analyses
## Multilevel meta-analysis
```{r}

#We use the effect sizes to fit a three-level meta-analysis model with random 
#effects at the study and estimate level in which we account for the dependence 
#of effect sizes by letting the sampling errors within studies to be correlated 
#with a correlation coefficient of 'rho'. We also apply robust variance 
#estimation (RVE) with small-sample adjustment.

rho = .5

  # read effect size datasets
  dat <- read.csv(file = "effect_sizes.csv", header = TRUE)
  
  # fitting multilevel model
  mlma <- conduct_mlma(dat = dat, rho = rho)
  mlma <- robust(mlma, cluster = study_id_1, clubSandwich = TRUE)
  
  # save output
  write_rds(mlma, "mlma_%s.rds")

  mlma
  

  
```


### Outliers on overall avoidant DMS
```{r}

boxplot(mlma$yi, plot=TRUE)$out 

# Extract the yi values into a data frame
data_mlma <- as.data.frame(mlma$yi)  
names(data_mlma) <- "yi"  

# Identify outliers
caseoutliers <- boxplot(data_mlma$yi, plot=FALSE)$out
caseoutliers <- round(caseoutliers, digits = 3)

# Round the yi values
data_mlma$rounded_yi <- round(data_mlma$yi, digits = 3)

# Logical vector for non-outliers
logical_vector <- !(data_mlma$rounded_yi %in% caseoutliers)

# Subset the data to exclude outliers
filtered_data_mlma <- data_mlma[logical_vector, , drop = FALSE]

# Print the filtered data
print(filtered_data_mlma)

#re-run model with 2 outliers removed

new_mlma <- rma(yi = filtered_data_mlma$yi, vi = mlma$vi[logical_vector], data = mlma$data[logical_vector, ])


summary(new_mlma)

```



#### Equivalence testing
```{r}

#To assess whether the effect sizes we obtained are practically or theoretically 
#of *relevance* (i.e., does the overall effect size fall within the boundaries 
#of a smallest effect size of interest or not?) we conducted equivalence tests. 
#We determined the smallest effect size of interest to be |.1|

 m <- read_rds("mlma_%s.rds")
  
  rob_se <- m$se
  es <- m$b[1]
  
  t <- TOSTmeta(ES = es,
                se = rob_se,
                low_eqbound_d=-0.1,
                high_eqbound_d=0.1,
                alpha=0.05)
  
  # save output
  write_rds(t, "equivalence_test_%s.rds")

  
```


```{r}

t


```


### Test the fit of the three-level model against the 2 two-level models
```{r}

overall <- conduct_mlma(dat = dat, rho = rho)

# Build a two-level model without within-study variance.
# Perform a likelihood-ratio-test to determine the significance of the within-study variance.
  dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat )
  dat$study_id_1 <- as.character(dat$study_id_1)
  dat$es_id <- as.character(dat$es_id)

V_mat <- vcalc(vi = vi,
                cluster = study_id_1,
                obs = es_id,
                data = dat,
                rho = rho)

modelnovar2 <- rma.mv(yi = yi, V = V_mat, random = list(~ 1 | study_id_1, ~ 1 | study_es_id),sigma2=c(0,NA), 
                      tdist=TRUE, data=dat)



anova(overall,modelnovar2)

# Build a two-level model without between-study variance;
# Perform a likelihood-ratio-test to determine the significance of the between-study variance.

modelnovar3 <- rma.mv(yi = yi, V = V_mat, random = list(~ 1 | study_id_1, ~ 1 | study_es_id),sigma2=c(0,NA), 
                      tdist=TRUE, data=dat)

anova(overall,modelnovar3)


```


### Variances
```{r}
# Determining how the total variance is distributed over the three levels of the meta-analytic model;
# Print the results in percentages on screen.
mlma

n <- length(dat$cor_vi)

list.inverse.variances <- 1 / (dat$cor_vi)

sum.inverse.variances <- sum(list.inverse.variances)

squared.sum.inverse.variances <- (sum.inverse.variances) ^ 2
list.inverse.variances.square <- 1 / (dat$cor_vi^2)
sum.inverse.variances.square <-sum(list.inverse.variances.square)
numerator <- (n - 1) * sum.inverse.variances
denominator <- squared.sum.inverse.variances -sum.inverse.variances.square
estimated.sampling.variance <- numerator / denominator
I2_1 <- (estimated.sampling.variance) / (mlma$sigma2[1]+ mlma$sigma2[2] + estimated.sampling.variance)
I2_2 <- (mlma$sigma2[1]) / (mlma$sigma2[1]+ mlma$sigma2[2] + estimated.sampling.variance)
I2_3 <- (mlma$sigma2[2]) / (mlma$sigma2[1]+ mlma$sigma2[2] + estimated.sampling.variance)
amountvariancelevel1 <- I2_1 * 100
amountvariancelevel2 <- I2_2 * 100
amountvariancelevel3 <- I2_3 * 100

amountvariancelevel1
amountvariancelevel2
amountvariancelevel3
```

### Sensitivity analysis
```{r}

overall_sensitivity <- conduct_sensitivity_rho(dat = dat, rho_vec = c(.1,.2,.3,.4,.5,.6,.7,.8,.9))

write_rds(overall_sensitivity, file = "overall_sensitivity_rho.rds")

plot_sensitivity_rho(dat = read_rds("overall_sensitivity_rho.rds"))

```

## Forest plot
```{r}

plot_forestplot_ma(m = read_rds("mlma_%s.rds"))

mlma

```


## Moderator testing
```{r}

# transform data into an escalc object
dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat )
df <- NULL
rho_vec <- seq(from = .1, to = .9, by = .1)

# Center age range moderator
dat$dec_diff_gmc <- scale(dat$dec_diff, scale=FALSE)
dat$culture_individualism_gmc <- scale(dat$culture_individualism, scale=FALSE)
dat$culture_powerdistance_gmc <- scale(dat$culture_powerdistance, scale=FALSE)
dat$culture_mtas_gmc <- scale(dat$culture_mtas, scale=FALSE)
dat$culture_uncertaintyavoidance_gmc <- scale(dat$culture_uncertaintyavoidance, 
                                              scale=FALSE)
dat$culture_longtermorientation_gmc <- scale(dat$culture_longtermorientation, 
                                             scale=FALSE)
dat$culture_indulgence_gmc <- scale(dat$culture_indulgence, scale=FALSE)

for (rho in rho_vec) {
  
  # create approx. V matrix assuming that the effect sizes within studies are correlated with a correlation coefficient of value 'rho'
  V_mat <- vcalc(vi = vi,
                 cluster = study_id_1,
                 obs = es_id,
                 data = dat,
                 rho = rho)
  
  m <- list()
  
  
  # fit multilevel models using approximate V matrix
  ## age range in decades as moderator------------------------------------------
  ### some studies are removed due to missing age information
  m[[1]] <- rma.mv(yi ~ 1 + dec_diff,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[1]] <- robust(m[[1]], cluster = study_id_1, clubSandwich = TRUE)

  
   ## ES metric as moderator----------------------------------------------------
  ## No reference level
  m[[2]] <- rma.mv(yi ~ 0 + cor_type,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[2]] <- robust(m[[2]], cluster = study_id_1, clubSandwich = TRUE)
 
  
  ### for extreme group design studies we calculate average prop. of females in the sample (weighted average).
  ###  some studies are removed due to missing gender information
  dat <- dat %>% 
    rowwise() %>% 
    mutate(prop_female_gen = 
             case_when(!is.na(gender_female_value) ~ gender_female_value)) %>% 
    ungroup()
  
  m[[3]] <- rma.mv(yi ~ 1 + prop_female_gen,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[3]] <- robust(m[[3]], cluster = study_id, clubSandwich = TRUE)
  
  ### Culture - Power distance as moderator-------------------------------------
  
  # Exclude NA
  datb <- dat[!(is.na(dat$culture_powerdistance)),] # exclude NA
  datb$study_id_1 <- as.factor(datb$study_id_1)
  datb$es_id <- as.factor(datb$es_id)
  
  V_matb <- vcalc(vi = vi,
                  cluster = study_id_1,
                  obs = es_id,
                  data = datb, 
                  rho = rho)
  
   m[[4]] <- rma.mv(yi ~ 1 + culture_powerdistance,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[4]] <- robust(m[[4]], cluster = study_id_1, clubSandwich = TRUE)
  
  
  ### Culture - Individualism as moderator--------------------------------------

  m[[5]] <- rma.mv(yi ~ 1 + culture_individualism,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[5]] <- robust(m[[5]], cluster = study_id_1, clubSandwich = TRUE)
  
  ### Culture - MTAS as moderator-----------------------------------------------

  m[[6]] <- rma.mv(yi ~ 1 + culture_mtas,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[6]] <- robust(m[[6]], cluster = study_id_1, clubSandwich = TRUE)
  
  ### Culture - Uncertainty avoidance as moderator--------------------------------------

  m[[7]] <- rma.mv(yi ~ 1 + culture_uncertaintyavoidance,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[7]] <- robust(m[[7]], cluster = study_id_1, clubSandwich = TRUE)
  
  ### Culture - Long-term orientation as moderator--------------------------------------

  
  m[[8]] <- rma.mv(yi ~ 1 + culture_longtermorientation,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[8]] <- robust(m[[8]], cluster = study_id_1, clubSandwich = TRUE)
  
  ### Culture - Indulgence as moderator--------------------------------------

  m[[9]] <- rma.mv(yi ~ 1 + culture_indulgence,
                   V = V_matb,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=datb,
                   digits=4)
  
  m[[9]] <- robust(m[[9]], cluster = study_id_1, clubSandwich = TRUE)
  
  
  ## Decision-style outcome as moderator-----------------------------------------
  ## Avoidance dv as reference
  m[[10]] <- rma.mv(yi ~ 1 + dv,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[10]] <- robust(m[[10]], cluster = study_id_1, clubSandwich = TRUE)
  

   ## Year of publication as moderator-----------------------------------------
  m[[11]] <- rma.mv(yi ~ 1 + year,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[11]] <- robust(m[[11]], cluster = study_id_1, clubSandwich = TRUE)
  
  ## Decision context of study as moderator-----------------------------------------
  ## General as reference level

  m[[12]] <- rma.mv(yi ~ 1 + context,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[12]] <- robust(m[[12]], cluster = study_id_1, clubSandwich = TRUE)
  
   # expand the list of models in a tidy format
  meta_reg_df <- NULL
  for (i in 1:length(m)) {
    
    res <- m[[i]]
    # could also use broom::tidy()
    res_df <- tibble(reg_num = i,
                     moderator = rownames(res$b),
                     estimate = res$b[,1],
                     se = res$se,
                     tval = res$zval,
                     ci_lb = res$ci.lb,
                     ci_ub = res$ci.ub,
                     pval = res$pval)
    
    
    meta_reg_df <- bind_rows(meta_reg_df,res_df)
    
    
    
  }
  
  meta_reg_df <- meta_reg_df %>% mutate(rho = rho)
  df <- df %>% bind_rows(meta_reg_df) %>% 
    mutate_if(is.numeric, round, 3)  %>% 
    write_csv("meta_reg.csv")
  
  }


df_format <- df %>%
  mutate_if(is.numeric, as.character)  %>% 
  filter(moderator != "intrcpt") %>% 
  filter(rho == .5) %>%
  mutate(reg_num = reg_num,
         est = estimate,
         se = se,
         tval = tval,
         pval = pval,
         ci95 = paste0(" [", ci_lb, ", ", ci_ub,"]"))  %>%
  select(moderator, est,se,tval, pval, ci95) %>% 
  write_csv("meta_reg_format.csv")

print("Meta-regression results with effect sizes saved")

  
  






```
 

### Covariate overview
```{r}

covariates <- c("cor_type", "dv")

# read effect size datasets
  dat <- read.csv(file = "effect_sizes.csv", header = TRUE)
  
  df <- NULL
  for (covar in covariates) {
    

    dt <- dat %>%
      group_by_at(covar) %>%          
      summarise(k = n(),
                predictor = covar) %>% 
      rename("level" = all_of(covar))
    
    df <- bind_rows(df, dt)
  }
  
  print(df)
  
  write.csv(df, file = "covariate_overview.csv")
  


```

### Multiple moderator model including all sig variables
```{r}

# read effect size datasets
dat <- read.csv(file = "effect_sizes.csv")

dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat )
dat$study_id_1 <- as.character(dat$study_id_1)
dat$es_id <- as.character(dat$es_id)
  
multiplemoderator <- rma.mv(yi,
                            V = vi,
                            random = ~ 1 | study_id_1/es_id,
                            data=dat,
                            mods = ~dv + cor_type,
                            tdist=TRUE)

summary(multiplemoderator, digits=3)

multiplemoderator <- robust(multiplemoderator, cluster = study_id_1, clubSandwich = TRUE)

```


## Egger's regression test

```{r}


### Egger's regression test

rho = .5
egger_df <- NULL
  
  for (preci in c("se", "invn")) {
    
    # read effect size datasets
    dat <- read.csv(file = "effect_sizes.csv")
    dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat)
    dat$study_id_1 <- as.character(dat$study_id_1)
    dat$es_id <- as.character(dat$es_id)
    
    # compute a "precision" index (standard error or inverse sample size)
    
    if (preci == "se") {
      dat$precision <- sqrt(dat$cor_vi)
    } 
    if (preci == "invn") {
      dat$precision <- 1/dat$n_incl_es
    } 
    
    # run meta-regression with "precision" as a predictor
    
    ### create approx. V matrix assuming that the effect sizes within studies
    ###  are correlated with a correlation coefficient of value 'rho'
    V_mat <- vcalc(vi = vi,
                   cluster = study_id_1,
                   obs = es_id,
                   data = dat,
                   rho = rho)
    
    ### Egger's Test: fit multilevel model using the approximate V matrix + 
    ### predictor to represent precision 
    egger <- rma.mv(yi ~ 1 + precision,  
                    V = V_mat,
                    random = ~ 1| study_id_1/es_id, 
                    data = dat)
    
    # apply RVE
    egger <- robust(egger, cluster = study_id_1, clubSandwich = TRUE)
    
    
    # could also use broom::tidy()
    res_df <- tibble(precision_indc = preci,
                     moderator = rownames(egger$b),
                     estimate = egger$b[,1],
                     se = egger$se,
                     tval = egger$zval,
                     ci_lb = egger$ci.lb,
                     ci_ub = egger$ci.ub,
                     pval = egger$pval)
    
    
    egger_df <- bind_rows(egger_df,res_df)
  }
  
  # save output
  write_rds(egger_df, file = "eggers.rds")


```

