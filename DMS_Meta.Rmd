---
title: "DMS_Meta"
author: "T.L"
date: "2024-05-07"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Libraries
```{r}

library(tidyverse) # data wrangling
library(janitor) # clean column names
library(metafor) # compute effect sizes
library(effectsize)# compute effect sizes
library(clubSandwich)
library(TOSTER)

source("compute_es.R")
source("conduct_mlma.R")
source("table_es_overview.R")
source("conduct_sensitivity_rho.R")
source("conduct_cma.R")
source("conduct_leave1out.R")

```


# Clean up data
```{r}

data <- read.csv(file = "2024-0520_review_Formatted.csv", header = TRUE)

data <- clean_names(data)

sapply(data, class)

# Clean up culture column into separate 

df1 <- data %>% separate(culture_of_sample_study_1, 
                         c("culture_powerdistance", "culture_individualism",
                           "culture_mtas", "culture_uncertaintyavoidance",
                           "culture_longtermorientation", "culture_indulgence"), 
                         ";")

df1$culture_powerdistance<-gsub("PD:","",as.character(df1$culture_powerdistance))
df1$culture_individualism<-gsub("Individualism:","",as.character(df1$culture_individualism))
df1$culture_mtas<-gsub("MTAS:","",as.character(df1$culture_mtas))
df1$culture_uncertaintyavoidance<-gsub("UA:","",as.character(df1$culture_uncertaintyavoidance))
df1$culture_longtermorientation<-gsub("LTO:","",as.character(df1$culture_longtermorientation))
df1$culture_indulgence<-gsub("Indulgence:","",as.character(df1$culture_indulgence))

sapply(df1, class)

df1$culture_powerdistance <- as.numeric(df1$culture_powerdistance)
df1$culture_individualism <- as.numeric(df1$culture_individualism)
df1$culture_mtas <- as.numeric(df1$culture_mtas)
df1$culture_uncertaintyavoidance <- as.numeric(df1$culture_uncertaintyavoidance)
df1$culture_longtermorientation <- as.numeric(df1$culture_longtermorientation)
df1$culture_indulgence <- as.numeric(df1$culture_indulgence)

# Fix up some names

df1 <- df1 %>% rename(country = country_in_which_the_study_conducted)

df1$country<-gsub("Other:","",as.character(df1$country))

df1 <- df1 %>% rename(topic = topic_of_decision_important_general_unknown_etc_study_1)

df1 <- df1 %>% rename(measure = type_of_avoidant_decision_making_measure_study_1)

df1 <- df1 %>% rename(sample_type = population_description_study_1)

df1 <- df1 %>% rename(analysis = analysis_type_study_1_avoidant_dv)

df1 <- df1 %>% mutate_all(na_if, "")

write.csv(df1, file = "prepped_meta_data.csv")

```


# Compute Effect Sizes
```{r}


df2 <- read.csv(file = "prepped_meta_data.csv")

compute_es(df2)

```


## Visualisation and overview table of data
```{r}

dat <- read.csv(file = "effect_sizes.csv", header = TRUE)

## There are duplicate rows - Unsure why. ## FIXED IT!!



dat %>% 
  ggplot(aes(x= cor_yi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= cor_vi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= log10(n_incl_es))) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample")

dat %>% 
  ggplot(aes(x= dec_diff)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample age Differences (decades)")



table1 <- table_es_overview(dat)

table1

```


# Analyses
## Multilevel meta-analysis
```{r}

#We use the effect sizes to fit a three-level meta-analysis model with random 
#effects at the study and estimate level in which we account for the dependence 
#of effect sizes by letting the sampling errors within studies to be correlated 
#with a correlation coefficient of 'rho'. We also apply robust variance 
#estimation (RVE) with small-sample adjustment.

rho = .5

  # read effect size datasets
  dat <- read.csv(file = "effect_sizes.csv", header = TRUE)
  
  # fitting multilevel model
  mlma <- conduct_mlma(dat = dat, rho = rho)
  mlma <- robust(mlma, cluster = study_id_1, clubSandwich = TRUE)
  
  # save output
  write_rds(mlma, "mlma_%s.rds")

  mlma
  

  
```


### Outliers on overall avoidant DMS
```{r}

boxplot(mlma$yi, plot=TRUE)$out 

# Extract the yi values into a data frame
data_mlma <- as.data.frame(mlma$yi)  
names(data_mlma) <- "yi"  

# Identify outliers
caseoutliers <- boxplot(data_mlma$yi, plot=FALSE)$out
caseoutliers <- round(caseoutliers, digits = 3)

# Round the yi values
data_mlma$rounded_yi <- round(data_mlma$yi, digits = 3)

# Logical vector for non-outliers
logical_vector <- !(data_mlma$rounded_yi %in% caseoutliers)

# Subset the data to exclude outliers
filtered_data_mlma <- data_mlma[logical_vector, , drop = FALSE]

# Print the filtered data
print(filtered_data_mlma)

#re-run model with 2 outliers removed

new_mlma <- rma(yi = filtered_data_mlma$yi, vi = mlma$vi[logical_vector], data = mlma$data[logical_vector, ])


summary(new_mlma)

```



#### Equivalence testing
```{r}

#To assess whether the effect sizes we obtained are practically or theoretically 
#of *relevance* (i.e., does the overall effect size fall within the boundaries 
#of a smallest effect size of interest or not?) we conducted equivalence tests. 
#We determined the smallest effect size of interest to be |.1|

 m <- read_rds("mlma_%s.rds")
  
  rob_se <- m$se
  es <- m$b[1]
  
  t <- TOSTmeta(ES = es,
                se = rob_se,
                low_eqbound_d=-0.1,
                high_eqbound_d=0.1,
                alpha=0.05)
  
  # save output
  write_rds(t, "equivalence_test_%s.rds")

  
```


```{r}

t


```


## Test the fit of the three-level model against the 2 two-level models
```{r}

overall <- conduct_mlma(dat = dat, rho = rho)

# Build a two-level model without within-study variance.
# Perform a likelihood-ratio-test to determine the significance of the within-study variance.
  dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat )
  dat$study_id_1 <- as.character(dat$study_id_1)
  dat$es_id <- as.character(dat$es_id)

V_mat <- vcalc(vi = vi,
                cluster = study_id_1,
                obs = es_id,
                data = dat,
                rho = rho)

modelnovar2 <- rma.mv(yi = yi, V = V_mat, random = list(~ 1 | study_id_1, ~ 1 | study_es_id),sigma2=c(0,NA), 
                      tdist=TRUE, data=dat)



anova(overall,modelnovar2)

# Build a two-level model without between-study variance;
# Perform a likelihood-ratio-test to determine the significance of the between-study variance.

modelnovar3 <- rma.mv(yi = yi, V = V_mat, random = list(~ 1 | study_id_1, ~ 1 | study_es_id),sigma2=c(0,NA), 
                      tdist=TRUE, data=dat)

anova(overall,modelnovar3)


```


### Variances
```{r}
# Determining how the total variance is distributed over the three levels of the meta-analytic model;
# Print the results in percentages on screen.

n <- length(dat$cor_vi)

list.inverse.variances <- 1 / (dat$cor_vi)

sum.inverse.variances <- sum(list.inverse.variances)

squared.sum.inverse.variances <- (sum.inverse.variances) ^ 2
list.inverse.variances.square <- 1 / (dat$cor_vi^2)
sum.inverse.variances.square <-sum(list.inverse.variances.square)
numerator <- (n - 1) * sum.inverse.variances
denominator <- squared.sum.inverse.variances -sum.inverse.variances.square
estimated.sampling.variance <- numerator / denominator
I2_1 <- (estimated.sampling.variance) / (overall$sigma2[1]+ overall$sigma2[2] + estimated.sampling.variance)
I2_2 <- (overall$sigma2[1]) / (overall$sigma2[1]+ overall$sigma2[2] + estimated.sampling.variance)
I2_3 <- (overall$sigma2[2]) / (overall$sigma2[1]+ overall$sigma2[2] + estimated.sampling.variance)
amountvariancelevel1 <- I2_1 * 100
amountvariancelevel2 <- I2_2 * 100
amountvariancelevel3 <- I2_3 * 100

amountvariancelevel1
amountvariancelevel2
amountvariancelevel3
```

## Moderator testing
```{r}

# transform data into an escalc object
dat <- escalc(yi = cor_yi, vi = cor_vi, data = dat )
df <- NULL
rho_vec <- seq(from = .1, to = .9, by = .1)


for (rho in rho_vec) {
  
  # create approx. V matrix assuming that the effect sizes within studies are correlated with a correlation coefficient of value 'rho'
  V_mat <- vcalc(vi = vi,
                 cluster = study_id_1,
                 obs = es_id,
                 data = dat,
                 rho = rho)
  
  m <- list()
  
  
  # fit multilevel models using approximate V matrix
  ## age range in decades as moderator
  ### some studies are removed due to missing age information
  m[[1]] <- rma.mv(yi ~ 1 + dec_diff,
                   V = V_mat,
                   random = ~ 1 | study_id_1/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[1]] <- robust(m[[1]], cluster = study_id_1, clubSandwich = TRUE)
}
m
  
  ### for extreme group design studies we calculate average prop. of females in the sample (weighted average).
  ###  some studies are removed due to missing gender information
  dat <- dat %>% 
    rowwise() %>% 
    mutate(prop_female_gen = 
             case_when(is.na(gender_female_value) & !is.na(young_prop_female) & !is.na(old_prop_female) ~ ((young_total_n/n_incl_es)*young_prop_female)+((old_total_n/n_incl_es)*old_prop_female),
                       !is.na(prop_female) ~ prop_female)) %>% 
    ungroup()
  
  m[[2]] <- rma.mv(yi ~ 1 + prop_female_gen,
                   V = V_mat,
                   random = ~ 1 | study_id/es_id, # random effect of study and estimate
                   data=dat,
                   digits=4)
  
  m[[2]] <- robust(m[[2]], cluster = study_id, clubSandwich = TRUE)
  
  
  

```


### Culture
```{r}

# Power distance

## filter effect size datasets
sdat <- dat[!(is.na(dat$culture_powerdistance)),]
  
  
## fitting multilevel model
culpd <- conduct_mlma(dat = sdat, rho = rho)
culpd <- robust(culpd, cluster = study_id_1, clubSandwich = TRUE)
  
  
## save output
write_rds(culpd, "mlma_culture_pd.rds")

culpd

# Individualism




# Gender - Pre-registered


# Decision topic - Pre-registered


# MDMQ or GDMS - Pre-registered


# Year of publication - Pre-registered


# Avoidance or dependence from GDMS

```


