---
title: "DMS_Meta"
author: "T.L"
date: "2024-05-07"
output: html_document
editor_options: 
  chunk_output_type: console
---

# Libraries
```{r}

library(tidyverse) # data wrangling
library(janitor) # clean column names
library(metafor) # compute effect sizes
library(effectsize)# compute effect sizes
library(clubSandwich)
library(TOSTER)

source("compute_es.R")
source("conduct_mlma.R")
source("table_es_overview.R")
source("conduct_sensitivity_rho.R")
source("conduct_cma.R")
source("conduct_leave1out.R")

```


# Clean up data
```{r}

data <- read.csv(file = "2024-0520_review_Formatted.csv", header = TRUE)

data <- clean_names(data)

sapply(data, class)

# Clean up culture column into separate 

df1 <- data %>% separate(culture_of_sample_study_1, 
                         c("culture_powerdistance", "culture_individualism",
                           "culture_mtas", "culture_uncertaintyavoidance",
                           "culture_longtermorientation", "culture_indulgence"), 
                         ";")

df1$culture_powerdistance<-gsub("PD:","",as.character(df1$culture_powerdistance))
df1$culture_individualism<-gsub("Individualism:","",as.character(df1$culture_individualism))
df1$culture_mtas<-gsub("MTAS:","",as.character(df1$culture_mtas))
df1$culture_uncertaintyavoidance<-gsub("UA:","",as.character(df1$culture_uncertaintyavoidance))
df1$culture_longtermorientation<-gsub("LTO:","",as.character(df1$culture_longtermorientation))
df1$culture_indulgence<-gsub("Indulgence:","",as.character(df1$culture_indulgence))

sapply(df1, class)

df1$culture_powerdistance <- as.numeric(df1$culture_powerdistance)
df1$culture_individualism <- as.numeric(df1$culture_individualism)
df1$culture_mtas <- as.numeric(df1$culture_mtas)
df1$culture_uncertaintyavoidance <- as.numeric(df1$culture_uncertaintyavoidance)
df1$culture_longtermorientation <- as.numeric(df1$culture_longtermorientation)
df1$culture_indulgence <- as.numeric(df1$culture_indulgence)

# Fix up some names

df1 <- df1 %>% rename(country = country_in_which_the_study_conducted)

df1$country<-gsub("Other:","",as.character(df1$country))

df1 <- df1 %>% rename(topic = topic_of_decision_important_general_unknown_etc_study_1)

df1 <- df1 %>% rename(measure = type_of_avoidant_decision_making_measure_study_1)

df1 <- df1 %>% rename(sample_type = population_description_study_1)

df1 <- df1 %>% rename(analysis = analysis_type_study_1_avoidant_dv)

df1 <- df1 %>% mutate_all(na_if, "")

write.csv(df1, file = "prepped_meta_data.csv")

```


# Compute Effect Sizes
```{r}


df2 <- read.csv(file = "prepped_meta_data.csv")

compute_es(df2)

```


## Visualisation and overview table of data
```{r}

dat <- read.csv(file = "effect_sizes.csv", header = TRUE)

## There are duplicate rows - Unsure why. ## FIXED IT!!



dat %>% 
  ggplot(aes(x= cor_yi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= cor_vi)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Estimate")

dat %>% 
  ggplot(aes(x= log10(n_incl_es))) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample")

dat %>% 
  ggplot(aes(x= dec_diff)) + 
  geom_density() +
  theme_bw() +
  ggtitle("Sample age Differences (decades)")



table1 <- table_es_overview(dat)

table1

```


# Analyses
## Multilevel meta-analysis
```{r}

#We use the effect sizes to fit a three-level meta-analysis model with random 
#effects at the study and estimate level in which we account for the dependence 
#of effect sizes by letting the sampling errors within studies to be correlated 
#with a correlation coefficient of 'rho'. We also apply robust variance 
#estimation (RVE) with small-sample adjustment.

rho = .5

  # read effect size datasets
  dat <- read.csv(file = "effect_sizes.csv", header = TRUE)
  
  # fitting multilevel model
  mlma <- conduct_mlma(dat = dat, rho = rho)
  mlma <- robust(mlma, cluster = study_id_1, clubSandwich = TRUE)
  
  # save output
  write_rds(mlma, "mlma_%s.rds")

  mlma
  
```


### Outliers on overall avoidant DMS
```{r}

boxplot(mlma$yi, plot=TRUE)$out 

# Extract the yi values into a data frame
data_mlma <- as.data.frame(mlma$yi)  
names(data_mlma) <- "yi"  

# Identify outliers
caseoutliers <- boxplot(data_mlma$yi, plot=FALSE)$out
caseoutliers <- round(caseoutliers, digits = 3)

# Round the yi values
data_mlma$rounded_yi <- round(data_mlma$yi, digits = 3)

# Logical vector for non-outliers
logical_vector <- !(data_mlma$rounded_yi %in% caseoutliers)

# Subset the data to exclude outliers
filtered_data_mlma <- data_mlma[logical_vector, , drop = FALSE]

# Print the filtered data
print(filtered_data_mlma)

#re-run model with 2 outliers removed

new_mlma <- rma(yi = filtered_data_mlma$yi, vi = mlma$vi[logical_vector], data = mlma$data[logical_vector, ])


summary(new_mlma)

```



#### Equivalence testing
```{r}

#To assess whether the effect sizes we obtained are practically or theoretically 
#of *relevance* (i.e., does the overall effect size fall within the boundaries 
#of a smallest effect size of interest or not?) we conducted equivalence tests. 
#We determined the smallest effect size of interest to be |.1|

 m <- read_rds("mlma_%s.rds")
  
  rob_se <- m$se
  es <- m$b[1]
  
  t <- TOSTmeta(ES = es,
                se = rob_se,
                low_eqbound_d=-0.1,
                high_eqbound_d=0.1,
                alpha=0.05)
  
  # save output
  write_rds(t, "equivalence_test_%s.rds")

```


### Moderator testing
```{r}



# Culture - Pre-registered


# Gender - Pre-registered


# Decision topic - Pre-registered


# MDMQ or GDMS - Pre-registered


# Year of publication - Pre-registered


# Avoidance or dependence from GDMS

```


